{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjsTGP4rP5ZB"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import os.path\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image, display, Markdown\n",
        "import matplotlib.cm as cm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import tensorflow as tf\n",
        "from time import perf_counter\n",
        "import seaborn as sns\n",
        "\n",
        "def printmd(string):\n",
        "    # Print with Markdowns    \n",
        "    display(Markdown(string))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtA74QzaP93Q"
      },
      "source": [
        "image_dir = Path('/content/drive/MyDrive/DRD/gaussian_filtered_images/gaussian_filtered_images')\n",
        "\n",
        "# Get filepaths and labels\n",
        "filepaths = list(image_dir.glob(r'**/*.png'))\n",
        "labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYmJzchcTOxi"
      },
      "source": [
        "filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
        "labels = pd.Series(labels, name='Label')\n",
        "\n",
        "# Concatenate filepaths and labels\n",
        "image_df = pd.concat([filepaths, labels], axis=1)\n",
        "\n",
        "# Shuffle the DataFrame and reset index\n",
        "image_df = image_df.sample(frac=1).reset_index(drop = True)\n",
        "\n",
        "# Show the result\n",
        "image_df.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f64hyoBTSB1"
      },
      "source": [
        "fig, axes = plt.subplots(nrows=3, ncols=4, figsize=(10, 7),\n",
        "                        subplot_kw={'xticks': [], 'yticks': []})\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(plt.imread(image_df.Filepath[i]))\n",
        "    ax.set_title(image_df.Label[i])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PehBULB6TVm3"
      },
      "source": [
        "vc = image_df['Label'].value_counts()\n",
        "plt.figure(figsize=(9,5))\n",
        "sns.barplot(x = vc.index, y = vc, palette = \"icefire\")\n",
        "plt.title(\"Number of pictures of each category\", fontsize = 15)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oyrs_NbTT55L"
      },
      "source": [
        "def create_gen():\n",
        "    # Load the Images with a generator and Data Augmentation\n",
        "    train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n",
        "        validation_split=0.1\n",
        "    )\n",
        "\n",
        "    test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n",
        "    )\n",
        "\n",
        "    train_images = train_generator.flow_from_dataframe(\n",
        "        dataframe=train_df,\n",
        "        x_col='Filepath',\n",
        "        y_col='Label',\n",
        "        target_size=(224, 224),\n",
        "        color_mode='rgb',\n",
        "        class_mode='categorical',\n",
        "        batch_size=32,\n",
        "        shuffle=True,\n",
        "        seed=0,\n",
        "        subset='training',\n",
        "        rotation_range=30, # Uncomment to use data augmentation\n",
        "        zoom_range=0.15,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.15,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode=\"nearest\"\n",
        "    )\n",
        "\n",
        "    val_images = train_generator.flow_from_dataframe(\n",
        "        dataframe=train_df,\n",
        "        x_col='Filepath',\n",
        "        y_col='Label',\n",
        "        target_size=(224, 224),\n",
        "        color_mode='rgb',\n",
        "        class_mode='categorical',\n",
        "        batch_size=32,\n",
        "        shuffle=True,\n",
        "        seed=0,\n",
        "        subset='validation',\n",
        "        rotation_range=30, # Uncomment to use data augmentation\n",
        "        zoom_range=0.15,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.15,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode=\"nearest\"\n",
        "    )\n",
        "\n",
        "    test_images = test_generator.flow_from_dataframe(\n",
        "        dataframe=test_df,\n",
        "        x_col='Filepath',\n",
        "        y_col='Label',\n",
        "        target_size=(224, 224),\n",
        "        color_mode='rgb',\n",
        "        class_mode='categorical',\n",
        "        batch_size=32,\n",
        "        shuffle=False\n",
        "    )\n",
        "    \n",
        "    return train_generator,test_generator,train_images,val_images,test_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRLwv249U_0I"
      },
      "source": [
        "def get_model(model):\n",
        "# Load the pretained model\n",
        "    kwargs =    {'input_shape':(224, 224, 3),\n",
        "                'include_top':False,\n",
        "                'weights':'imagenet',\n",
        "                'pooling':'avg'}\n",
        "    \n",
        "    pretrained_model = model(**kwargs)\n",
        "    pretrained_model.trainable = False\n",
        "    \n",
        "    inputs = pretrained_model.input\n",
        "\n",
        "    x = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\n",
        "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "\n",
        "    outputs = tf.keras.layers.Dense(5, activation='softmax')(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2miLJk8eVDbg"
      },
      "source": [
        "train_df, test_df = train_test_split(image_df, train_size=0.9, shuffle=True, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcEhtamAVGp2"
      },
      "source": [
        "models = {\n",
        "    \"DenseNet121\": {\"model\":tf.keras.applications.DenseNet121, \"perf\":0},\n",
        "    \"DenseNet169\": {\"model\":tf.keras.applications.DenseNet169, \"perf\":0},\n",
        "    \"InceptionResNetV2\": {\"model\":tf.keras.applications.InceptionResNetV2, \"perf\":0},\n",
        "    \"InceptionV3\": {\"model\":tf.keras.applications.InceptionV3, \"perf\":0},\n",
        "    \"MobileNet\": {\"model\":tf.keras.applications.MobileNet, \"perf\":0},\n",
        "    \"MobileNetV2\": {\"model\":tf.keras.applications.MobileNetV2, \"perf\":0},\n",
        "    \"ResNet101\": {\"model\":tf.keras.applications.ResNet101, \"perf\":0},\n",
        "    \"ResNet50\": {\"model\":tf.keras.applications.ResNet50, \"perf\":0},\n",
        "    \"VGG16\": {\"model\":tf.keras.applications.VGG16, \"perf\":0},\n",
        "    \"VGG19\": {\"model\":tf.keras.applications.VGG19, \"perf\":0}\n",
        "}\n",
        "\n",
        "# Create the generators\n",
        "train_generator,test_generator,train_images,val_images,test_images=create_gen()\n",
        "print('\\n')\n",
        "\n",
        "# Fit the models\n",
        "for name, model in models.items():\n",
        "    \n",
        "    # Get the model\n",
        "    m = get_model(model['model'])\n",
        "    models[name]['model'] = m\n",
        "    \n",
        "    start = perf_counter()\n",
        "    \n",
        "    # Fit the model\n",
        "    history = m.fit(train_images,validation_data=val_images,epochs=1,verbose=1)\n",
        "    \n",
        "    # Sav the duration, the train_accuracy and the val_accuracy\n",
        "    duration = perf_counter() - start\n",
        "    duration = round(duration,2)\n",
        "    models[name]['perf'] = duration\n",
        "    print(f\"{name:20} trained in {duration} sec\")\n",
        "    \n",
        "    val_acc = history.history['val_accuracy']\n",
        "    models[name]['val_acc'] = [round(v,4) for v in val_acc]\n",
        "    \n",
        "    train_acc = history.history['accuracy']\n",
        "    models[name]['train_accuracy'] = [round(v,4) for v in train_acc]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQbizsS_VLDt"
      },
      "source": [
        "models_result = []\n",
        "\n",
        "for name, v in models.items():\n",
        "    models_result.append([ name, \n",
        "                          models[name]['train_accuracy'][-1],\n",
        "                          models[name]['val_acc'][-1], \n",
        "                          models[name]['perf']])\n",
        "    \n",
        "df_results = pd.DataFrame(models_result, \n",
        "                          columns = ['model','train_accuracy','val_accuracy','Training time (sec)'])\n",
        "df_results.sort_values(by='val_accuracy', ascending=False, inplace=True)\n",
        "df_results.reset_index(inplace=True,drop=True)\n",
        "df_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7yhQxnpfUWL"
      },
      "source": [
        "plt.figure(figsize = (15,5))\n",
        "sns.barplot(x = 'model', y = 'train_accuracy', data = df_results)\n",
        "plt.title('Accuracy on the Training Set (after 1 epoch)', fontsize = 15)\n",
        "plt.ylim(0,1)\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGFpu8SYfWpf"
      },
      "source": [
        "pretrained_model = tf.keras.applications.InceptionResNetV2(\n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    pooling='avg'\n",
        ")\n",
        "\n",
        "pretrained_model.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_Xx_3THgJAw"
      },
      "source": [
        "inputs = pretrained_model.input\n",
        "\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "\n",
        "outputs = tf.keras.layers.Dense(5, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy','AUC']\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_images,\n",
        "    validation_data=val_images,\n",
        "    batch_size = 32,\n",
        "    epochs=100,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=20,\n",
        "            restore_best_weights=True\n",
        "        )\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1gUSn2CkYK-"
      },
      "source": [
        "pd.DataFrame(history.history)[['accuracy','val_accuracy']].plot()\n",
        "plt.title(\"Accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olRrhrQ0kYj_"
      },
      "source": [
        "pd.DataFrame(history.history)[['loss','val_loss']].plot()\n",
        "plt.title(\"Loss\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a47hp6ckakw"
      },
      "source": [
        "results = model.evaluate(test_images, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBpZAYkJkclT"
      },
      "source": [
        "printmd(\" ## Test Loss: {:.5f}\".format(results[0]))\n",
        "printmd(\"## Accuracy on the test set: {:.2f}%\".format(results[1] * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BvUhWvlkefP"
      },
      "source": [
        "pred = model.predict(test_images)\n",
        "pred = np.argmax(pred,axis=1)\n",
        "\n",
        "# Map the label\n",
        "labels = (train_images.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "pred = [labels[k] for k in pred]\n",
        "\n",
        "# Display the result\n",
        "print(f'The first 5 predictions: {pred[:5]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFCFvETKkhLm"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "y_test = list(test_df.Label)\n",
        "from sklearn import metrics\n",
        "print('Accuracy:', np.round(metrics.accuracy_score(y_test, pred),5))\n",
        "print('Precision:', np.round(metrics.precision_score(y_test, pred, average='weighted'),5))\n",
        "print('Recall:', np.round(metrics.recall_score(y_test,pred, average='weighted'),5))\n",
        "print('F1 Score:', np.round(metrics.f1_score(y_test, pred, average='weighted'),5))\n",
        "print('Cohen Kappa Score:', np.round(metrics.cohen_kappa_score(y_test, pred),5))\n",
        "print(classification_report(y_test, pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpEwAixDk6o5"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "cf_matrix = confusion_matrix(y_test, pred, normalize='true')\n",
        "plt.figure(figsize = (10,6))\n",
        "sns.heatmap(cf_matrix, annot=True, xticklabels = sorted(set(y_test)), yticklabels = sorted(set(y_test)))\n",
        "plt.title('Normalized Confusion Matrix')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgJPLogelAIj"
      },
      "source": [
        "image_df_red = image_df.copy()\n",
        "image_df_red['Label'] = image_df_red['Label'].apply(lambda x: x if x == 'No_DR' else 'DR')\n",
        "image_df_red.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPVpV8srlC5L"
      },
      "source": [
        "vc = image_df_red['Label'].value_counts()\n",
        "plt.figure(figsize=(9,5))\n",
        "sns.barplot(x = vc.index, y = vc, palette = \"rocket\")\n",
        "plt.title(\"Number of pictures of each category\", fontsize = 15)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtVBG7RhlEwe"
      },
      "source": [
        "train_df, test_df = train_test_split(image_df_red, train_size=0.9, shuffle=True, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CujX7PbElHOK"
      },
      "source": [
        "# Create the generators\n",
        "train_generator,test_generator,train_images,val_images,test_images=create_gen()\n",
        "\n",
        "# Load the pretained model\n",
        "pretrained_model = tf.keras.applications.InceptionResNetV2(\n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    pooling='avg'\n",
        ")\n",
        "\n",
        "pretrained_model.trainable = False\n",
        "\n",
        "\n",
        "inputs = pretrained_model.input\n",
        "\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "\n",
        "outputs = tf.keras.layers.Dense(2, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy','AUC']\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_images,\n",
        "    validation_data=val_images,\n",
        "    batch_size = 32,\n",
        "    epochs=200,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=3,\n",
        "            restore_best_weights=True\n",
        "        )\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWuBOOO6lXNB"
      },
      "source": [
        "pd.DataFrame(history.history)[['accuracy','val_accuracy']].plot()\n",
        "plt.title(\"Accuracy\")\n",
        "plt.show()\n",
        "\n",
        "pd.DataFrame(history.history)[['loss','val_loss']].plot()\n",
        "plt.title(\"Loss\")\n",
        "plt.show()\n",
        "\n",
        "results = model.evaluate(test_images, verbose=0)\n",
        "\n",
        "printmd(\" ## Test Loss: {:.5f}\".format(results[0]))\n",
        "printmd(\"## Accuracy on the test set: {:.2f}%\".format(results[1] * 100))\n",
        "print('\\n')\n",
        "\n",
        "# Predict the label of the test_images\n",
        "pred = model.predict(test_images)\n",
        "pred = np.argmax(pred,axis=1)\n",
        "\n",
        "# Map the label\n",
        "labels = (train_images.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "pred = [labels[k] for k in pred]\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "y_test = list(test_df.Label)\n",
        "from sklearn import metrics\n",
        "print('Accuracy:', np.round(metrics.accuracy_score(y_test,pred),5))\n",
        "print('Precision:', np.round(metrics.precision_score(y_test,pred, average='weighted'),5))\n",
        "print('Recall:', np.round(metrics.recall_score(y_test,pred, average='weighted'),5))\n",
        "print('F1 Score:', np.round(metrics.f1_score(y_test,pred, average='weighted'),5))\n",
        "print('Cohen Kappa Score:', np.round(metrics.cohen_kappa_score(y_test,pred),5))\n",
        "print(classification_report(y_test, pred))\n",
        "\n",
        "cf_matrix = confusion_matrix(y_test, pred, normalize='true')\n",
        "plt.figure(figsize = (10,6))\n",
        "sns.heatmap(cf_matrix, annot=True, xticklabels = sorted(set(y_test)), yticklabels = sorted(set(y_test)))\n",
        "plt.title('Normalized Confusion Matrix')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}